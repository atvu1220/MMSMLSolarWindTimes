function [trainedClassifier, validationAccuracy] = GenerateModel2(trainingData)
    % [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
    % returns a trained classifier and its accuracy. This code recreates the
    % classification model trained in Classification Learner app. Use the
    % generated code to automate training the same model with new data, or to
    % learn how to programmatically train models.
    %
    %  Input:
    %      trainingData: a table containing the same predictor and response
    %       columns as imported into the app.
    %
    %  Output:
    %      trainedClassifier: a struct containing the trained classifier. The
    %       struct contains various fields with information about the trained
    %       classifier.
    %
    %      trainedClassifier.predictFcn: a function to make predictions on new
    %       data.
    %
    %      validationAccuracy: a double containing the accuracy in percent. In
    %       the app, the History list displays this overall accuracy score for
    %       each model.
    %
    % Use the code to train the model with new data. To retrain your
    % classifier, call the function from the command line with your original
    % data or new data as the input argument trainingData.
    %
    % For example, to retrain a classifier trained with the original data set
    % T, enter:
    %   [trainedClassifier, validationAccuracy] = trainClassifier(T)
    %
    % To make predictions with the returned 'trainedClassifier' on new data T2,
    % use
    %   yfit = trainedClassifier.predictFcn(T2)
    %
    % T2 must be a table containing at least the same predictor columns as used
    % during training. For details, enter:
    %   trainedClassifier.HowToPredict
    
    % Auto-generated by MATLAB on 20-Aug-2019 05:23:45
    
    
    % Extract predictors and response
    % This code processes the data into the right shape for training the
    % model.
    inputTable = trainingData;
    predictorNames = {'Bx' 'By' 'Bz' 'Bmag' 'N' 'Vx' 'Vy' 'Vz' 'Vmag',...
    'e1','e2','e3','e4','e5','e6','e7','e8','e9','e10','e11','e12','e13','e14','e15','e16','e17','e18','e19','e20','e21','e22','e23','e24','e25','e26','e27','e28','e29','e30','e31','e32',...
    'Rx' 'Ry' 'Rz' 'R',...
    'massflux',...
    'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','c26','c27','c28','c29','c30','c31','c32'};
    predictors = inputTable(:, predictorNames);
    response = inputTable.Response;
%     isCategoricalPredictor = [false, false, false, false, false, false, false, false, false, false, false, false, false];
    
    % Data transformation: Select subset of the features
    % This code selects the same subset of features as were used in the app.
    includedPredictorNames = predictors.Properties.VariableNames([false false false  true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true]);
    predictors = predictors(:,includedPredictorNames);
    %isCategoricalPredictor = isCategoricalPredictor([false false false true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true  true true true true true true true true true true]);
    
    % Train a classifier
    % This code specifies all the classifier options and trains the classifier.
    template = templateTree(...
        'MaxNumSplits', 200);
    classificationEnsemble = fitcensemble(...
        predictors, ...
        response, ...
        'Method', 'AdaBoostM2', ...
        'NumLearningCycles', 200, ...
        'Learners', template, ...
        'LearnRate', 0.1, ...
        'ClassNames', categorical({'Magnetosheath'; 'Solar Wind'; 'Magnetosphere';'NightSide'}, {'Magnetosheath' 'Solar Wind' 'Magnetosphere' 'NightSide'}));
    
    % Create the result struct with predict function
    predictorExtractionFcn = @(t) t(:, predictorNames);
    featureSelectionFcn = @(x) x(:,includedPredictorNames);
    ensemblePredictFcn = @(x) predict(classificationEnsemble, x);
    trainedClassifier.predictFcn = @(x) ensemblePredictFcn(featureSelectionFcn(predictorExtractionFcn(x)));
    
    % Add additional fields to the result struct
    trainedClassifier.RequiredVariables = {'Bx' 'By' 'Bz' 'Bmag' 'N' 'Vx' 'Vy' 'Vz' 'Vmag',...
    'e1','e2','e3','e4','e5','e6','e7','e8','e9','e10','e11','e12','e13','e14','e15','e16','e17','e18','e19','e20','e21','e22','e23','e24','e25','e26','e27','e28','e29','e30','e31','e32',...
    'Rx' 'Ry' 'Rz' 'R',...
    'massflux',...
    'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','c26','c27','c28','c29','c30','c31','c32'};
    trainedClassifier.ClassificationEnsemble = classificationEnsemble;
    trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2018b.';
    trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');
    
    % Extract predictors and response
    % This code processes the data into the right shape for training the
    % model.
    inputTable = trainingData;
    predictorNames = {'Bx' 'By' 'Bz' 'Bmag' 'N' 'Vx' 'Vy' 'Vz' 'Vmag',...
    'e1','e2','e3','e4','e5','e6','e7','e8','e9','e10','e11','e12','e13','e14','e15','e16','e17','e18','e19','e20','e21','e22','e23','e24','e25','e26','e27','e28','e29','e30','e31','e32',...
    'Rx' 'Ry' 'Rz' 'R',...
    'massflux',...
    'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','c26','c27','c28','c29','c30','c31','c32'}
    predictors = inputTable(:, predictorNames);
    response = inputTable.Response;
%     isCategoricalPredictor = [false, false, false, false, false, false, false, false, false, false, false, false, false];
    
    % Perform cross-validation
    partitionedModel = crossval(trainedClassifier.ClassificationEnsemble, 'KFold', 5);
    
    % Compute validation predictions
    [validationPredictions, validationScores] = kfoldPredict(partitionedModel);
    
    % Compute validation accuracy
    validationAccuracy = 1 - kfoldLoss(partitionedModel, 'LossFun', 'ClassifError');
